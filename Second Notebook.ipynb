{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Second Notebook\n",
    "\n",
    "This notebook builds on My First Notebook. Some of the things it covers:\n",
    "\n",
    "* Looking at the Simple Sentiment analysis example\n",
    "* Opening files\n",
    "* Counting things\n",
    "* Tokenizing\n",
    "* Counting words\n",
    "* Finding words\n",
    "* Concording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on IPython\n",
    "\n",
    "* Adding cells\n",
    "* Moving cells - cutting and pasting\n",
    "* Closing and quitting\n",
    "* Running cells "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Strings\n",
    "Note the use of \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is a text with\n",
      "many lines.\n",
      "A line is represented with an escaped \n",
      "\n",
      "OK?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text1 = '''\n",
    "This is a text with\n",
    "many lines.\n",
    "A line is represented with an escaped \\n\n",
    "OK?\n",
    "'''\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting\n",
    "\n",
    "Here you can see tokenizing with the .split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'This is a text with', 'many lines.', 'A line is represented with an escaped ', '', 'OK?', '']\n"
     ]
    }
   ],
   "source": [
    "text2 = text1.split(\"\\n\")\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing\n",
    "\n",
    "We discussed different ways of tokenizing. Here is a way using the .split() method. This splits a string on the spaces (or other characters if specified.) The limitation is that trailing punctuation ends up with the words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theText = \"We have some delightful new food in the cafeteria. Awesome!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theTokens = theText.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " 'have',\n",
       " 'some',\n",
       " 'delightful',\n",
       " 'new',\n",
       " 'food',\n",
       " 'in',\n",
       " 'the',\n",
       " 'cafeteria.',\n",
       " 'Awesome!!!']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theTokens2 = text1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'text',\n",
       " 'with',\n",
       " 'many',\n",
       " 'lines.',\n",
       " 'A',\n",
       " 'line',\n",
       " 'is',\n",
       " 'represented',\n",
       " 'with',\n",
       " 'an',\n",
       " 'escaped',\n",
       " 'OK?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theTokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'text.', 'It', 'has', 'sentences,', 'like', 'this.']\n"
     ]
    }
   ],
   "source": [
    "rawT = \"This is a text. It has sentences, like this.\"\n",
    "print(rawT.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation\n",
    "\n",
    "We have two problems. Punctuation and case. What can we do about them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'text', 'it', 'has', 'sentences', 'like', 'this']\n"
     ]
    }
   ],
   "source": [
    "rawT2 = rawT.lower()\n",
    "editedT = rawT2.replace('.',\" \").replace(',',\" \").replace('!',\" \").replace('?',\" \")\n",
    "listWords = editedT.split(None)\n",
    "print(listWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "is\n",
      "a\n",
      "text\n",
      "it\n",
      "has\n",
      "sentences\n",
      "like\n",
      "this\n"
     ]
    }
   ],
   "source": [
    "for word in listWords:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'text', 'it', 'has', 'sentences', 'like', 'this']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "theTokens = re.findall(r'\\b\\w[\\w-]*\\b', rawT.lower())\n",
    "print(theTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a URL\n",
    "\n",
    "Now we will get a big text from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This string has 550321 characters\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "poeUrl = \"http://www.gutenberg.org/files/2147/2147-0.txt\"\n",
    "poeString = urllib.request.urlopen(poeUrl).read().decode().strip()\n",
    "print(\"This string has\", len(poeString), \"characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Finding stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poeString.find(\"Poe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gar Allan Poe, by Ed\n"
     ]
    }
   ],
   "source": [
    "print(poeString[(45 - 10):(45 + 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to find? poe\n",
      " was spoken, the half-starved poet received $10! Less\n",
      "than \n"
     ]
    }
   ],
   "source": [
    "firstInstance = poeString.find(input(\"What do you want to find? \"))\n",
    "context = 30 \n",
    "print(poeString[firstInstance-context : firstInstance+context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to find?poe\n",
      "Occurrences of  poe :  124\n"
     ]
    }
   ],
   "source": [
    "textToFind = input(\"What do you want to find?\").lower()\n",
    "instances = poeString.lower().count(textToFind)\n",
    "print(\"Occurrences of \", textToFind, \": \", instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2690:  was spoken, the half-starved poet received $10! Less\r\n",
      "than \n",
      "=================\n",
      "2685: guage was spoken, the half-starved poet received $10! Less\r\n",
      "\n",
      "=================\n",
      "2680: h language was spoken, the half-starved poet received $10! L\n",
      "=================\n",
      "2675: nglish language was spoken, the half-starved poet received $\n",
      "=================\n",
      "2670: he\r\n",
      "English language was spoken, the half-starved poet recei\n",
      "=================\n",
      "2665: ver the\r\n",
      "English language was spoken, the half-starved poet \n",
      "=================\n",
      "2660: wherever the\r\n",
      "English language was spoken, the half-starved \n",
      "=================\n",
      "2655: died wherever the\r\n",
      "English language was spoken, the half-sta\n",
      "=================\n",
      "2650:  parodied wherever the\r\n",
      "English language was spoken, the hal\n",
      "=================\n",
      "2645: d and parodied wherever the\r\n",
      "English language was spoken, th\n",
      "=================\n",
      "2640: ecited and parodied wherever the\r\n",
      "English language was spoke\n",
      "=================\n",
      "2635: ad, recited and parodied wherever the\r\n",
      "English language was \n",
      "=================\n",
      "2630: s, read, recited and parodied wherever the\r\n",
      "English language\n",
      "=================\n",
      "2625: months, read, recited and parodied wherever the\r\n",
      "English lan\n",
      "=================\n",
      "2620:  few months, read, recited and parodied wherever the\r\n",
      "Englis\n",
      "=================\n",
      "2615: hin a few months, read, recited and parodied wherever the\r\n",
      "E\n",
      "=================\n",
      "2610: , within a few months, read, recited and parodied wherever t\n",
      "=================\n",
      "2605: \r\n",
      "and, within a few months, read, recited and parodied where\n",
      "=================\n",
      "2600: 1845,\r\n",
      "and, within a few months, read, recited and parodied \n",
      "=================\n",
      "2595: d in 1845,\r\n",
      "and, within a few months, read, recited and paro\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "def printKWIC(context,search): \n",
    "    location = 0\n",
    "    theCurrentLoc = 0 \n",
    "    for i in range(20):\n",
    "        location = poeString[theCurrentLoc:].find(search)\n",
    "        toPrint = str(location) + \": \" + poeString[location-context : location+context] + \"\\n=================\"\n",
    "        print(toPrint) \n",
    "        theCurrentLoc = theCurrentLoc + 5\n",
    "        \n",
    "printKWIC(30,\"poe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
