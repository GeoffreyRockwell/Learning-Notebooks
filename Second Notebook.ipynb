{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Second Notebook\n",
    "\n",
    "This notebook builds on My First Notebook. Some of the things it covers:\n",
    "\n",
    "* Looking at the Simple Sentiment analysis example\n",
    "* Opening files\n",
    "* Counting things\n",
    "* Tokenizing\n",
    "* Counting words\n",
    "* Finding words\n",
    "* Concording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on IPython\n",
    "\n",
    "* Adding cells\n",
    "* Moving cells - cutting and pasting\n",
    "* Closing and quitting\n",
    "* Running cells "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Strings\n",
    "Note the use of \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is a text with\n",
      "many lines.\n",
      "A line is represented with an escaped \n",
      "\n",
      "OK?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text1 = '''\n",
    "This is a text with\n",
    "many lines.\n",
    "A line is represented with an escaped \\n\n",
    "OK?\n",
    "'''\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting\n",
    "\n",
    "Here you can see tokenizing with the .split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'This is a text with', 'many lines.', 'A line is represented with an escaped ', '', 'OK?', '']\n"
     ]
    }
   ],
   "source": [
    "text2 = text1.split(\"\\n\")\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing\n",
    "\n",
    "We discussed different ways of tokenizing. Here is a way using the .split() method. This splits a string on the spaces (or other characters if specified.) The limitation is that trailing punctuation ends up with the words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theText = \"We have some delightful new food in the cafeteria. Awesome!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theTokens = theText.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " 'have',\n",
       " 'some',\n",
       " 'delightful',\n",
       " 'new',\n",
       " 'food',\n",
       " 'in',\n",
       " 'the',\n",
       " 'cafeteria.',\n",
       " 'Awesome!!!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theTokens2 = text1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'text',\n",
       " 'with',\n",
       " 'many',\n",
       " 'lines.',\n",
       " 'A',\n",
       " 'line',\n",
       " 'is',\n",
       " 'represented',\n",
       " 'with',\n",
       " 'an',\n",
       " 'escaped',\n",
       " 'OK?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theTokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'text.', 'It', 'has', 'sentences,', 'like', 'this.']\n"
     ]
    }
   ],
   "source": [
    "rawT = \"This is a text. It has sentences, like this.\"\n",
    "print(rawT.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation\n",
    "\n",
    "We have two problems. Punctuation and case. What can we do about them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'text', 'it', 'has', 'sentences', 'like', 'this']\n"
     ]
    }
   ],
   "source": [
    "rawT2 = rawT.lower()\n",
    "editedT = rawT2.replace('.',\" \").replace(',',\" \").replace('!',\" \").replace('?',\" \")\n",
    "listWords = editedT.split(None)\n",
    "print(listWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "is\n",
      "a\n",
      "text\n",
      "it\n",
      "has\n",
      "sentences\n",
      "like\n",
      "this\n"
     ]
    }
   ],
   "source": [
    "for word in listWords:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'text', 'it', 'has', 'sentences', 'like', 'this']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "theTokens = re.findall(r'\\b\\w[\\w-]*\\b', rawT.lower())\n",
    "print(theTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a URL\n",
    "\n",
    "Now we will get a big text from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This string has 550321 characters\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "poeUrl = \"http://www.gutenberg.org/files/2147/2147-0.txt\"\n",
    "poeString = urllib.request.urlopen(poeUrl).read().decode().strip()\n",
    "print(\"This string has\", len(poeString), \"characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Finding stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poeString.find(\"Poe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gar Allan Poe, by Ed\n"
     ]
    }
   ],
   "source": [
    "print(poeString[(45 - 10):(45 + 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to find? Poe\n",
      "rg's The Works of Edgar Allan Poe, by Edgar Allan Poe\n",
      "\n",
      "Thi\n"
     ]
    }
   ],
   "source": [
    "firstInstance = poeString.find(input(\"What do you want to find? \"))\n",
    "context = 30 \n",
    "print(poeString[firstInstance-context : firstInstance+context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to find?Poe\n",
      "Occurrences of  poe :  124\n"
     ]
    }
   ],
   "source": [
    "textToFind = input(\"What do you want to find?\").lower()\n",
    "instances = poeString.lower().count(textToFind)\n",
    "print(\"Occurrences of \", textToFind, \": \", instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 : \n",
      "llan Poe\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at \n",
      "104 : \n",
      "is eBook is for the use of anyone anywhere at no cost and wi\n",
      "90 : \n",
      "llan Poe\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at \n",
      "104 : \n",
      "is eBook is for the use of anyone anywhere at no cost and wi\n",
      "90 : \n",
      "llan Poe\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at \n"
     ]
    }
   ],
   "source": [
    "def printKWIC(context,search): \n",
    "    location = 0\n",
    "    theCurrentLoc = 0\n",
    "    for i in range(5):\n",
    "        location = poeString[theCurrentLoc:].find(search)\n",
    "        print(location,\": \")\n",
    "        print(poeString[location-context : location+context])\n",
    "        theCurrentLoc = location + 30\n",
    "        \n",
    "printKWIC(30,\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
