{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with a corpus\n",
    "\n",
    "This notebook shows how you can use a CSV to work with a collection of documents in a folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "\n",
    "As usual, we first import the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv, re, collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking directory\n",
    "\n",
    "We need to check where the directory of texts is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExampleTable.csv             \u001b[34mTexts\u001b[m\u001b[m/\r\n",
      "Hume Enquiry.txt             Third Notebook.ipynb\r\n",
      "My First Notebook.ipynb      Web Scraping.ipynb\r\n",
      "Second Notebook.ipynb        Working with a Corpus.ipynb\r\n",
      "Test.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting and Reading Texts\n",
    "\n",
    "In this loop we go through a CSV with rows for each item of the corpus we want to work with. We have included a test so we can grab only those that meet some condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phil.txt', 'theo.txt', 'grcv.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "with open('Texts/mycorpus.csv', 'r') as file: # This makes sure that file is closed after reading\n",
    "    data = csv.reader(file)\n",
    "    # This goes through all the rows in the CSV\n",
    "    for row in data:\n",
    "        # This tests a condition to decide if we want to process the text.\n",
    "        if row[4] != \"error\": \n",
    "            files.append(row[3]) # This puts all the data into a list\n",
    "file.closed\n",
    "fileNames = files[1:] # This gets all items but the first (which is a label)\n",
    "fileNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Directory\n",
    "\n",
    "Now we need to change directory to make sure we process the files in the *Texts* directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/grockwel/Sync/Rockwell IPython Stuff/LearningNotebooks/LearningNotebooks/Texts\n"
     ]
    }
   ],
   "source": [
    "cd Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grcv.txt      mycorpus.csv  phil.txt      results.csv   theo.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing all the Texts\n",
    "\n",
    "Here we do something with all the texts. In this case we read them and add them to a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159322"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theBigText = \"\"\n",
    "for item in fileNames:\n",
    "    with open(item, 'r') as file:\n",
    "        theBigText += file.read()\n",
    "    file.closed\n",
    "theBigText[:300]\n",
    "len(theBigText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get a dictionary of word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1310"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = re.findall(r'\\b\\w[\\w-]*\\b', theBigText.lower())\n",
    "theTypesCount = {}\n",
    "theTypes = set(tokens)\n",
    "\n",
    "for item in theTypes:\n",
    "    theTypesCount[item]= (tokens.count(item))\n",
    "\n",
    "theTypesCount[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With is next command you can check the count for any word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theTypesCount[\"university\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of High Frequency Words\n",
    "\n",
    "This takes the dictionary (which can't be sorted) and turns it into a list of tuples. (Tuples are lists with two items.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 1310],\n",
       " ['of', 805],\n",
       " ['and', 651],\n",
       " ['at', 645],\n",
       " ['on', 565],\n",
       " ['a', 497],\n",
       " ['in', 491],\n",
       " ['for', 461],\n",
       " ['university', 346],\n",
       " ['humanities', 328],\n",
       " ['conference', 233],\n",
       " ['presented', 222],\n",
       " ['with', 202],\n",
       " ['digital', 200],\n",
       " ['to', 179],\n",
       " ['by', 163],\n",
       " ['is', 139],\n",
       " ['s', 135],\n",
       " ['computing', 135],\n",
       " ['text', 132],\n",
       " ['research', 132],\n",
       " ['june', 125],\n",
       " ['paper', 119],\n",
       " ['2011', 114],\n",
       " ['2014', 114],\n",
       " ['2012', 114],\n",
       " ['2013', 109],\n",
       " ['may', 109],\n",
       " ['2010', 102],\n",
       " ['was', 94]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listTuples = []\n",
    "for w in sorted(theTypesCount, key=theTypesCount.get, reverse=True):\n",
    "    theTuple = [w,theTypesCount[w]]\n",
    "    listTuples.append(theTuple)\n",
    "\n",
    "listTuples[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Word Frequencies\n",
    "\n",
    "Now we will run the process all over of opening files in order to build a table of word counts or frequencies for each individual file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first function will **count** the tokens for each word in the list provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wordCounter(text,words):\n",
    "    tokens = re.findall(r'\\b\\w[\\w-]*\\b', text.lower())\n",
    "    listCounts = []\n",
    "    for word in words:\n",
    "        listCounts.append(tokens.count(word))\n",
    "        \n",
    "    return listCounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second fuction will calculate the **relative frequency** for each word in the list provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordFreqCounter(text,words):\n",
    "    tokens = re.findall(r'\\b\\w[\\w-]*\\b', text.lower())\n",
    "    listFreqs = []\n",
    "    numTokens = len(tokens)\n",
    "    for word in words:\n",
    "        listFreqs.append(tokens.count(word)/numTokens)\n",
    "        \n",
    "    return listFreqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Files and Calculate \n",
    "\n",
    "This is the main loop that opens each file and does calculations for each word provided in each file. It builds a list of lists (or table) of results. \n",
    "\n",
    "**Note:** that you need to provide the list words you want counted. You can use the list of high frequency words above that was generated from all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['university', 'humanities', 'conference', 'research', 'banana'],\n",
       " ['phil.txt',\n",
       "  0.005250875145857643,\n",
       "  0.01575262543757293,\n",
       "  0.027421236872812137,\n",
       "  0.0029171528588098016,\n",
       "  0.0],\n",
       " ['theo.txt',\n",
       "  0.0,\n",
       "  0.0054525627044711015,\n",
       "  0.006543075245365322,\n",
       "  0.0016357688113413304,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfWords2Count = [\"university\",\"humanities\",\"conference\",\"research\",\"banana\"]\n",
    "listOflists = []\n",
    "listOflists.append(listOfWords2Count)\n",
    "for item in fileNames:\n",
    "    with open(item, 'r') as file:\n",
    "        theText = file.read()\n",
    "    file.closed\n",
    "    # If you want just word counts use wordCounter function.\n",
    "    # Otherwise use the wordFreqCounter function.\n",
    "    localCounts = [item] + wordFreqCounter(theText,listOfWords2Count)\n",
    "    listOflists.append(localCounts)\n",
    "    \n",
    "listOflists[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Out the Table\n",
    "\n",
    "Now we write out the table to a new CSV. Make sure you change the file name if you don't want overwrite the existing file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "with open(\"results.csv\", 'w', newline='') as csvfile:\n",
    "    resultsWriter = csv.writer(csvfile, delimiter=',',)\n",
    "    for item in listOflists:\n",
    "        resultsWriter.writerow(item)\n",
    "        \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results CSV can now be manipulated in a spreadsheet program like Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
